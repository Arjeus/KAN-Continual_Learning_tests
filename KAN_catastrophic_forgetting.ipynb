{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "a-td3yfwzemE",
    "ExecuteTime": {
     "end_time": "2024-07-03T11:22:11.451587Z",
     "start_time": "2024-07-03T11:22:09.647536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, utils\n",
    "from tqdm import tqdm\n",
    "\n",
    "from efficient_kan.kan import KAN\n",
    "from kan_convolutional import KANLinear\n",
    "from kan_convolutional.KANConv import KAN_Convolutional_Layer\n",
    "from torchkan.KANvolver import KANvolver as kanv\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TRAININGSET + TESTSET DEFINITION"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset = [datasets.MNIST, datasets.CIFAR10][1]\n",
    "dataset_name = dataset.__name__.lower()\n",
    "input_size = 28 * 28 if dataset == datasets.MNIST \\\n",
    "    else 3 * 32 * 32 if dataset == datasets.CIFAR10 \\\n",
    "    else -1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                # transforms.Normalize((0.5,), (0.5,))\n",
    "                                ])\n",
    "# Train set. Here we sort the MNIST by digits and disable data shuffling\n",
    "train_dataset = dataset(root='./data', train=True, download=True, transform=transform)\n",
    "sorted_indices = sorted(range(len(train_dataset) // 1), key=lambda idx: train_dataset.targets[idx])\n",
    "train_subset = Subset(train_dataset, sorted_indices)\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=False)\n",
    "\n",
    "# MultiTask training sets\n",
    "train_loader_tasks = []\n",
    "indices = []\n",
    "for k in range(5):\n",
    "    indices.append(list(\n",
    "        filter(lambda idx: train_dataset.targets[idx] in range(k * 2, k * 2 + 2), range(len(train_dataset)))))\n",
    "    train_loader_tasks.append(\n",
    "        DataLoader(Subset(train_dataset, indices[-1]), batch_size=64, shuffle=True))\n",
    "\n",
    "# Test set\n",
    "test_dataset = dataset(root='./data', train=False, download=True, transform=transform)\n",
    "test_subset = Subset(test_dataset, range(len(test_dataset) // 1))\n",
    "test_loader = DataLoader(test_subset, batch_size=64, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trainset visualizer\n",
    "The following code prints the images of the 5 domain IL scenarios. This way we can clearly see that for the MNIST dataset each task contains a pair of digits (0-1, 2-3, etc.), while for CIFAR10 each task contains a pair of objects (car-airplane, bird-dog, deer-dog, frog-horse and truck-ship)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    # img = (img / 2 + 0.5).numpy()\n",
    "    img = img.numpy()\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_images(class_index, num_images=16):\n",
    "    dataiter = iter(train_loader_tasks[class_index])\n",
    "    images, labels = next(dataiter)\n",
    "    imshow(utils.make_grid(images))\n",
    "\n",
    "\n",
    "for class_index in range(5):\n",
    "    print(f\"TASK ID = {class_index}\")\n",
    "    show_images(class_index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ARCHITECTURES DEFINITION\n",
    "The various Fully Connected and Conv-based architectures employ the log_softmax() function on the logits. This indicates that a NLLLoss loss function should be used instead of Cross Entropy. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, checkpoint: str | None = None):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = [input_size, 28 * 28, 256, 10] if dataset == datasets.MNIST \\\n",
    "            else [input_size, 32 * 32, 512, 10] if dataset == datasets.CIFAR10 \\\n",
    "            else []\n",
    "        self.fc1 = nn.Linear(self.layers[0], self.layers[1])\n",
    "        self.fc2 = nn.Linear(self.layers[1], self.layers[2])\n",
    "        self.fc3 = nn.Linear(self.layers[2], self.layers[3])\n",
    "        if checkpoint:\n",
    "            self.load_state_dict(torch.load(checkpoint))\n",
    "            self.eval()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.layers[0])\n",
    "        # x = (x / 0.5 - 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# MLP\n",
    "class MLP_Normalized(nn.Module):\n",
    "    def __init__(self, checkpoint: str | None = None):\n",
    "        super(MLP_Normalized, self).__init__()\n",
    "        self.layers = [input_size, 28 * 28, 256, 10] if dataset == datasets.MNIST \\\n",
    "            else [input_size, 32 * 32, 512, 10] if dataset == datasets.CIFAR10 \\\n",
    "            else []\n",
    "        self.fc1 = nn.Linear(self.layers[0], self.layers[1])\n",
    "        self.fc2 = nn.Linear(self.layers[1], self.layers[2])\n",
    "        self.fc3 = nn.Linear(self.layers[2], self.layers[3])\n",
    "        if checkpoint:\n",
    "            self.load_state_dict(torch.load(checkpoint))\n",
    "            self.eval()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.layers[0])\n",
    "        x = (x / 0.5 - 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# KAN\n",
    "class Efficient_KAN(nn.Module):\n",
    "    def __init__(self, device=device, checkpoint: str | None = None):\n",
    "        super(Efficient_KAN, self).__init__()\n",
    "        self.layers = [input_size, 128, 10] if dataset == datasets.MNIST \\\n",
    "            else [input_size, 128, 10] if dataset == datasets.CIFAR10 \\\n",
    "            else []\n",
    "        self.model = KAN(self.layers).to(device)\n",
    "        if checkpoint:\n",
    "            self.load_state_dict(torch.load(checkpoint))\n",
    "            self.eval()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.layers[0])\n",
    "        x = self.model(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Efficient_KAN_non_Normalized(nn.Module):\n",
    "    def __init__(self, device=device, checkpoint: str | None = None):\n",
    "        super(Efficient_KAN_non_Normalized, self).__init__()\n",
    "        self.layers = [input_size, 128, 10] if dataset == datasets.MNIST \\\n",
    "            else [input_size, 128, 10] if dataset == datasets.CIFAR10 \\\n",
    "            else []\n",
    "        self.model = KAN(self.layers).to(device)\n",
    "        if checkpoint:\n",
    "            self.load_state_dict(torch.load(checkpoint))\n",
    "            self.eval()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.layers[0])\n",
    "        x = (x / 0.5 - 1)\n",
    "        x = self.model(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# KAN_Convolutional_Layer + MLP\n",
    "class CKAN_BN(nn.Module):\n",
    "    def __init__(self, device: str = device):\n",
    "        super().__init__()\n",
    "        self.conv1 = KAN_Convolutional_Layer(\n",
    "            n_convs=5,\n",
    "            kernel_size=(3, 3),\n",
    "            device=device\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(5)\n",
    "\n",
    "        self.conv2 = KAN_Convolutional_Layer(\n",
    "            n_convs=5,\n",
    "            kernel_size=(3, 3),\n",
    "            device=device\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(25)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(\n",
    "            kernel_size=(2, 2)\n",
    "        )\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        self.linear1 = nn.Linear(625, 256)\n",
    "        self.linear2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        x = self.pool1(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# KAN_Convolutional_Layer + MLP (without Batch Norm)\n",
    "class KANC_MLP(nn.Module):\n",
    "    def __init__(self, device: str = device):\n",
    "        super().__init__()\n",
    "        self.conv1 = KAN_Convolutional_Layer(\n",
    "            n_convs=5,\n",
    "            kernel_size=(3, 3),\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        self.conv2 = KAN_Convolutional_Layer(\n",
    "            n_convs=5,\n",
    "            kernel_size=(3, 3),\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(\n",
    "            kernel_size=(2, 2)\n",
    "        )\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        self.linear1 = nn.Linear(625, 256)\n",
    "        self.linear2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Conv2d + KAN\n",
    "class NormalConvsKAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NormalConvsKAN, self).__init__()\n",
    "        # Convolutional layer, assuming an input with 1 channel (grayscale image)\n",
    "        # and producing 16 output channels, with a kernel size of 3x3\n",
    "        self.conv1 = nn.Conv2d(1, 5, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(5, 5, kernel_size=3, padding=1)\n",
    "\n",
    "        # Max pooling layer\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Flatten layer\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # KAN layer\n",
    "        self.kan1 = KANLinear(\n",
    "            245,\n",
    "            10,\n",
    "            grid_size=10,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.01,\n",
    "            scale_base=1,\n",
    "            scale_spline=1,\n",
    "            base_activation=nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[0, 1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.kan1(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Conv2d + MLP + (Dropout)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.layers = [1, 64 * 7 * 7, 256, 10] if dataset == datasets.MNIST \\\n",
    "            else [3, 64 * 8 * 8, 256, 10] if dataset == datasets.CIFAR10 \\\n",
    "            else []\n",
    "\n",
    "        self.conv1 = nn.Conv2d(self.layers[0], 32, kernel_size=5, padding='same')\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5, padding='same')\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding='same')\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding='same')\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.layers[1], self.layers[2])\n",
    "        self.fc2 = nn.Linear(self.layers[2], self.layers[3])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        #x = self.dropout1(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.maxpool(x)\n",
    "        #x = self.dropout2(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# KAN_Convolutional_Layer + KAN\n",
    "class KKAN_Convolutional_Network(nn.Module):\n",
    "    def __init__(self, device: str = device):\n",
    "        super().__init__()\n",
    "        self.conv1 = KAN_Convolutional_Layer(\n",
    "            n_convs=5,\n",
    "            kernel_size=(3, 3),\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        self.conv2 = KAN_Convolutional_Layer(\n",
    "            n_convs=5,\n",
    "            kernel_size=(3, 3),\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(\n",
    "            kernel_size=(2, 2)\n",
    "        )\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        self.kan1 = KANLinear(\n",
    "            625,\n",
    "            10,\n",
    "            grid_size=10,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.01,\n",
    "            scale_base=1,\n",
    "            scale_spline=1,\n",
    "            base_activation=nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[0, 1],\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.flat(x)\n",
    "\n",
    "        x = self.kan1(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Conv2d + MLP\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        self.layers = [1, 245, 10] if dataset == datasets.MNIST \\\n",
    "            else [3, 320, 10] if dataset == datasets.CIFAR10 \\\n",
    "            else []\n",
    "\n",
    "\n",
    "        self.conv1 = nn.Conv2d(self.layers[0], 5, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(5, 5, kernel_size=3, padding=1)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc = nn.Linear(self.layers[1], self.layers[2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# KANvolver This works only on MNIST for now. The source code should be adjusted.\n",
    "class KANvolver(nn.Module):\n",
    "    def __init__(self, device=device, checkpoint: str | None = None):\n",
    "        super(KANvolver, self).__init__()\n",
    "        self.model = kanv([10]).to(device)\n",
    "        if checkpoint:\n",
    "            self.load_state_dict(torch.load(checkpoint))\n",
    "            self.eval()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TRAIN() AND TEST() FUNCTIONS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train(model, checkpoint, optimizer, start_epoch=0, epochs=5, on_epoch_end=None, lr=0, loader=None,\n",
    "          task_id=None):\n",
    "    if loader is None:\n",
    "        loader = train_loader\n",
    "    criterion = nn.NLLLoss()\n",
    "    # scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.996)\n",
    "    for epoch in range(start_epoch, epochs + start_epoch):\n",
    "        model.train()\n",
    "        epoch_start = time.time_ns()\n",
    "        with tqdm(loader) as pbar:\n",
    "            for i, (images, labels) in enumerate(pbar):\n",
    "                # if model.__class__.__name__ in ['MLP', 'Efficient_KAN', 'Efficient_KAN_non_Normalized']:\n",
    "                #     images = images.view(-1, input_size)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(images.to(device))\n",
    "                loss = criterion(output, labels.to(device))\n",
    "                loss.backward()\n",
    "                optimizer.step(closure=lambda: loss)\n",
    "                accuracy = (output.argmax(dim=1) == labels.to(device)).float().mean()\n",
    "                pbar.set_postfix(loss=loss.item(), accuracy=accuracy.item(), lr=optimizer.param_groups[0]['lr'])\n",
    "                # scheduler.step()\n",
    "        print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n",
    "        epoch_duration = (time.time_ns() - epoch_start) // 1000000\n",
    "        if on_epoch_end is not None:\n",
    "            on_epoch_end(model, epoch, loss.item(), epoch_duration, lr, task_id)\n",
    "        # torch.save(model.state_dict(), f'{checkpoint}_ep{epoch + 1}.pth')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    criterion = nn.NLLLoss()\n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "    val_accuracy = 0\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            # if model.__class__.__name__ in ['MLP', 'Efficient_KAN', 'Efficient_KAN_non_Normalized']:\n",
    "            #     images = images.view(-1, input_size)\n",
    "            output = model(images.to(device))\n",
    "            loss = criterion(output, labels.to(device))\n",
    "            predictions.extend(output.argmax(dim=1).to('cpu').numpy())\n",
    "            ground_truths.extend(labels.to('cpu').numpy())\n",
    "            val_accuracy += (output.argmax(dim=1) == labels.to(device)).float().mean().item()\n",
    "    val_accuracy /= len(test_loader)\n",
    "    print(f\"Accuracy: {val_accuracy}\")\n",
    "    return loss.item(), ground_truths, predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# INTRA and INTER DATASET TESTS\n",
    "This class holds all relevant information about a training + test epoch. All the information needed to compute a confusion matrix is stored in the labels[] and predictions[] lists. Each serialised file takes about 300KiB, so they were added to the gitignore file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class EpochStat:\n",
    "    @staticmethod\n",
    "    def loadModelStats(name, dir=f'results/{dataset_name}/intra/', subdir='') -> list['EpochStat']:\n",
    "        return sorted([pickle.load(open(f'{dir}{subdir}{file}', 'rb')) for file in\n",
    "                       filter(lambda e: name == '_'.join(e.split('_')[:-1]), os.listdir(f'{dir}{subdir}'))],\n",
    "                      key=lambda e: e.epoch)\n",
    "\n",
    "    def __init__(self, name, epoch, train_loss=0, test_loss=0, labels=None, predictions=None, epoch_duration=0, lr=0,\n",
    "                 train_losses=None, train_accuracies=None, task_id=None):\n",
    "        self.name = name\n",
    "        self.train_loss = train_loss\n",
    "        self.test_loss = test_loss\n",
    "        self.epoch = epoch\n",
    "        self.predictions = predictions\n",
    "        self.labels = labels\n",
    "        self.epoch_duration = epoch_duration\n",
    "        self.lr = lr\n",
    "        self.train_losses = train_losses\n",
    "        self.train_accuracies = train_accuracies\n",
    "        self.task_id = task_id\n",
    "\n",
    "    def save(self, dir=f'results/{dataset_name}/intra/'):\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "        pickle.dump(self, open(f'{dir}{self.name}_epoch{self.epoch}.pickle', 'wb'))\n",
    "\n",
    "    def get_accuracy(self):\n",
    "        accuracy = 0\n",
    "        for label, prediction in zip(self.labels, self.predictions):\n",
    "            if label == prediction:\n",
    "                accuracy += 1\n",
    "        return accuracy / len(self.labels)\n",
    "\n",
    "\n",
    "def onEpochEnd(model, epoch, train_loss, epoch_duration, lr, task_id):\n",
    "    test_loss, labels, predictions = test(model)\n",
    "    stat = EpochStat(model.__class__.__name__, epoch, train_loss, test_loss, labels, predictions, epoch_duration,\n",
    "                     lr, [], [], task_id)\n",
    "    stat.save(\n",
    "        dir=f'results/{dataset_name}/intra/lr_{round(math.log10(lr))}/' if task_id is None else f'results/{dataset_name}/inter/lr_{round(math.log10(lr))}/')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## INTRA DATASET TEST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for lr in [1e-5, 1e-6]:\n",
    "    models = [Efficient_KAN(), MLP(), Efficient_KAN_non_Normalized(), MLP_non_Normalized(),\n",
    "              CKAN_BN(), KANC_MLP(), NormalConvsKAN(), ConvNet(),\n",
    "              KKAN_Convolutional_Network(), SimpleCNN(), KANvolver()]\n",
    "    print(f'Using lr={lr} ------------------------------------')\n",
    "    for model in [x.to(device) for x in models[:2]]:\n",
    "        print(f'Training model={model.__class__.__name__}')\n",
    "        train(model, f'results/{dataset_name}/intra/{model.__class__.__name__}', epochs=18, start_epoch=0,\n",
    "              optimizer=optim.Adam(model.parameters(), lr=lr), on_epoch_end=onEpochEnd, lr=lr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## INTER DATASET TEST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for epochs, lr in zip([4], [1e-4]):\n",
    "    models = [MLP(), Efficient_KAN(),\n",
    "              CKAN_BN(), KANC_MLP(), NormalConvsKAN(),\n",
    "              # ConvNet(),\n",
    "              KKAN_Convolutional_Network(), SimpleCNN(), KANvolver()]\n",
    "    print(f'Using lr={lr} ------------------------------------')\n",
    "    for model in [x.to(device) for x in models[:2]]:\n",
    "        print(f'Training model={model.__class__.__name__}')\n",
    "        for i, task in enumerate(train_loader_tasks):\n",
    "            print(f'Training on task {i}')\n",
    "            train(model, f'results/{dataset_name}/inter/{model.__class__.__name__}', epochs=epochs,\n",
    "                  start_epoch=i * epochs, optimizer=optim.Adam(model.parameters(), lr=lr), on_epoch_end=onEpochEnd,\n",
    "                  lr=lr, loader=task, task_id=i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RESULTS PLOTTING"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "models = [MLP(), Efficient_KAN(), MLP_Normalized(), Efficient_KAN_non_Normalized(),\n",
    "          CKAN_BN(), KANC_MLP(), NormalConvsKAN(),\n",
    "          KKAN_Convolutional_Network(), SimpleCNN(), KANvolver()]\n",
    "for lr in [1e-4,1e-5,1e-6,1e-7]:\n",
    "    fig, ax = plt.subplots()\n",
    "    batches = [\n",
    "        0,\n",
    "        5923,\n",
    "        6742,\n",
    "        5958,\n",
    "        6131,\n",
    "        5842,\n",
    "        5421,\n",
    "        5918,\n",
    "        6265,\n",
    "        5851,\n",
    "        # 5949,\n",
    "    ]\n",
    "    granularity = 1\n",
    "    for name in list(map(lambda e: e.__class__.__name__, models[:2])):\n",
    "        stats = EpochStat.loadModelStats(name, dir=f'results/{dataset_name}/inter/',\n",
    "                                         subdir=f'lr_{round(math.log10(lr))}/')\n",
    "        ax.plot(list(map(lambda e: e.get_accuracy(), stats))[:], label=name, marker='o')\n",
    "        # ax.plot(list(map(lambda e: e.train_accuracies, stats))[0][::granularity], label=name)\n",
    "    plt.legend()\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    # ax.set_xticks([x // 64 // granularity for x in itertools.accumulate(batches)])\n",
    "    # ax.set_xticklabels(range(10))\n",
    "    # plt.vlines(x=[x // 64 // granularity for x in itertools.accumulate(batches)], ymin=0, ymax=1, colors='black',\n",
    "    #            alpha=0.65, linestyles='dashed')\n",
    "    # plt.xlabel('Train Digits Batches', fontdict={'fontsize': 14})\n",
    "    # plt.ylabel('Train batch Loss', fontdict={'fontsize': 14})\n",
    "    # plt.title('Train batch loss spikes show up when a new digit is submitted', fontdict={'fontsize': 16})\n",
    "    plt.xlabel('Epoch', fontdict={'fontsize': 14})\n",
    "    plt.ylabel('Test Accuracy', fontdict={'fontsize': 14})\n",
    "    plt.title(f'INTER dataset with lr=e{round(math.log10(lr))}', fontdict={'fontsize': 16})\n",
    "    plt.vlines(x=range(0, 90, 18)[1:], ymin=0.05, ymax=0.15, colors='black', alpha=0.65, linestyles='dashed')\n",
    "    fig.set_size_inches(18, 10)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CONFUSION MATRICES PLOTTING"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "models = [MLP_non_Normalized(), Efficient_KAN(),\n",
    "          CKAN_BN(), KANC_MLP(), NormalConvsKAN(), ConvNet(),\n",
    "          KKAN_Convolutional_Network(), SimpleCNN()]\n",
    "plt.rc('font', size=18)\n",
    "for lr in [1e-5]:\n",
    "    for name in list(map(lambda e: e.__class__.__name__, models[:2])):\n",
    "        stats = EpochStat.loadModelStats(name, dir=f'results/{dataset_name}/intra/',\n",
    "                                         subdir=f'lr_{round(math.log10(lr))}/')\n",
    "        for stat in stats[:]:\n",
    "            cm = confusion_matrix(stat.labels, stat.predictions, labels=range(10))\n",
    "            disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(10))\n",
    "            disp.plot()\n",
    "            fig = disp.ax_.get_figure()\n",
    "            fig.set_figwidth(8)\n",
    "            fig.set_figheight(8)\n",
    "            plt.figtext(0.445, 0.85, f\"{name.replace('Efficient_KAN', 'KAN')} Epoch: {stat.epoch}\", ha='center',\n",
    "                        fontsize=22)\n",
    "            fig.savefig(f'png/{dataset_name}/intra/lr_{round(math.log10(lr))}/{name} ep{stat.epoch}.png')"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  }
 ]
}
