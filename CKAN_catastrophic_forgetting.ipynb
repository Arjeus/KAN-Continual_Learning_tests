{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "a-td3yfwzemE",
    "ExecuteTime": {
     "end_time": "2024-06-07T21:49:17.739733Z",
     "start_time": "2024-06-07T21:49:17.719700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from kan_convolutional.KANConv import KAN_Convolutional_Layer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "# Train set. Here we sort the MNIST by digits and disable data shuffling\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "sorted_indices = sorted(range(len(train_dataset)//10), key=lambda idx: train_dataset.targets[idx])\n",
    "# sorted_indices = range(len(train_dataset)//10)\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, sorted_indices)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "# Test set\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NepArtgMuvo3",
    "outputId": "1def6b8f-2fda-423b-fb06-731f01e99cc1",
    "ExecuteTime": {
     "end_time": "2024-06-07T21:54:23.551462Z",
     "start_time": "2024-06-07T21:54:23.322007Z"
    }
   },
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train(model, checkpoint, epochs=5):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
    "    # scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.996)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        with tqdm(train_loader) as pbar:\n",
    "            for i, (images, labels) in enumerate(pbar):\n",
    "                optimizer.zero_grad()\n",
    "                output = model(images.to(device))\n",
    "                loss = criterion(output, labels.to(device))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                accuracy = (output.argmax(dim=1) == labels.to(device)).float().mean()\n",
    "                pbar.set_postfix(loss=loss.item(), accuracy=accuracy.item(), lr=optimizer.param_groups[0]['lr'])\n",
    "                # scheduler.step()\n",
    "        print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n",
    "        torch.save(model.state_dict(), checkpoint)"
   ],
   "metadata": {
    "id": "jwrKUPn3vyDb",
    "ExecuteTime": {
     "end_time": "2024-06-07T21:54:10.017424Z",
     "start_time": "2024-06-07T21:54:09.997406Z"
    }
   },
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def validate(model):\n",
    "    model.eval()\n",
    "    vals=[0]*10\n",
    "    val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            output = model(images.to(device))\n",
    "            for out in output.argmax(dim=1):\n",
    "              vals[out.item()]+=1\n",
    "            val_accuracy += (output.argmax(dim=1) == labels.to(device)).float().mean().item()\n",
    "    val_accuracy /= len(test_loader)\n",
    "    print(vals)\n",
    "    print(f\"Accuracy: {val_accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T21:53:12.959078Z",
     "start_time": "2024-06-07T21:53:12.949568Z"
    }
   },
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CKAN_BN(nn.Module):\n",
    "    def __init__(self,device: str = 'cpu'):\n",
    "        super().__init__()\n",
    "        self.conv1 = KAN_Convolutional_Layer(\n",
    "            n_convs = 5,\n",
    "            kernel_size= (3,3),\n",
    "            device = device\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(5)\n",
    "\n",
    "        self.conv2 = KAN_Convolutional_Layer(\n",
    "            n_convs = 5,\n",
    "            kernel_size = (3,3),\n",
    "            device = device\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(25)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(\n",
    "            kernel_size=(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.flat = nn.Flatten() \n",
    "        \n",
    "        self.linear1 = nn.Linear(625, 256)\n",
    "        self.linear2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "       \n",
    "        x = self.pool1(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T21:46:20.261786Z",
     "start_time": "2024-06-07T21:46:20.240280Z"
    }
   },
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "source": [
    "ckan_model = CKAN_BN(device=device).to(device)\n",
    "train(ckan_model,'checkpoint/ckan_mnist_no_shuffle2.pth')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jCXm_Ahav3ON",
    "outputId": "378dc5a4-530f-48f8-f22c-780d0b5a0a0e",
    "ExecuteTime": {
     "end_time": "2024-06-07T21:55:22.854055Z",
     "start_time": "2024-06-07T21:54:30.285902Z"
    }
   },
   "execution_count": 53,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:16<00:00,  5.78it/s, accuracy=0.375, loss=1.94, lr=1e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.9429854154586792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:15<00:00,  5.91it/s, accuracy=0.417, loss=1.94, lr=1e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.9387669563293457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:16<00:00,  5.78it/s, accuracy=0.438, loss=1.93, lr=1e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.934876561164856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 22/94 [00:03<00:12,  5.65it/s, accuracy=0, loss=2.8, lr=1e-6] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[53], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m ckan_model \u001B[38;5;241m=\u001B[39m CKAN_BN(device\u001B[38;5;241m=\u001B[39mdevice)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mckan_model\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcheckpoint/ckan_mnist_no_shuffle2.pth\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[51], line 10\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, checkpoint, epochs)\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (images, labels) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(pbar):\n\u001B[0;32m      9\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 10\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(output, labels\u001B[38;5;241m.\u001B[39mto(device))\n\u001B[0;32m     12\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[35], line 33\u001B[0m, in \u001B[0;36mCKAN_BN.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     30\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn1(x)\n\u001B[0;32m     31\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool1(x)\n\u001B[1;32m---> 33\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     34\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn2(x)\n\u001B[0;32m     36\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool1(x)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\KAN_tests\\kan_convolutional\\KANConv.py:82\u001B[0m, in \u001B[0;36mKAN_Convolutional_Layer.forward\u001B[1;34m(self, x, update_grid)\u001B[0m\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: torch\u001B[38;5;241m.\u001B[39mTensor, update_grid\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m     80\u001B[0m     \u001B[38;5;66;03m# If there are multiple convolutions, apply them all\u001B[39;00m\n\u001B[0;32m     81\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_convs\u001B[38;5;241m>\u001B[39m\u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 82\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmultiple_convs_kan_conv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvs\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkernel_size\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;66;03m# If there is only one convolution, apply it\u001B[39;00m\n\u001B[0;32m     85\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mforward(x)\n",
      "File \u001B[1;32m~\\PycharmProjects\\KAN_tests\\kan_convolutional\\convolution.py:75\u001B[0m, in \u001B[0;36mmultiple_convs_kan_conv2d\u001B[1;34m(matrix, kernels, kernel_side, stride, dilation, padding, device)\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m channel \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_channels):\n\u001B[0;32m     74\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m kern \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_convs):\n\u001B[1;32m---> 75\u001B[0m         matrix_out[:,kern  \u001B[38;5;241m+\u001B[39m channel\u001B[38;5;241m*\u001B[39mn_convs,:,:] \u001B[38;5;241m=\u001B[39m kernels[kern]\u001B[38;5;241m.\u001B[39mconv\u001B[38;5;241m.\u001B[39mforward(\u001B[43mconv_groups\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43mchannel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflatten\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m)\u001B[38;5;241m.\u001B[39mreshape((batch_size,h_out,w_out))\n\u001B[0;32m     76\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m matrix_out\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 0, 2, 2724, 1357, 900, 37, 100, 2833, 2027]\n",
      "Accuracy: 0.15764331210191082\n"
     ]
    }
   ],
   "source": [
    "model = CKAN_BN(device=device).to(device)\n",
    "model.load_state_dict(torch.load('checkpoint/ckan_mnist_no_shuffle2.pth'))\n",
    "validate(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T21:55:39.729819Z",
     "start_time": "2024-06-07T21:55:25.732615Z"
    }
   },
   "execution_count": 54
  }
 ]
}
