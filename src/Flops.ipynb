{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:09:18.403746Z",
     "start_time": "2024-07-04T15:09:13.834480Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "# from torchsummary import summary\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "from kan import KAN\n",
    "from efficient_kan import KAN as EffKAN\n",
    "from kan_convolutional import KANLinear\n",
    "from kan_convolutional.KANConv import KAN_Convolutional_Layer\n",
    "from torchkan.KANvolver import KANvolver as kanv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552a7b37",
   "metadata": {},
   "source": [
    "# Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b276dbf3596400",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f3dfbe7f5efa945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:10:08.334331Z",
     "start_time": "2024-06-19T14:10:08.329808Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden):\n",
    "        super(MLP, self).__init__()\n",
    "        # self.fc1 = nn.Linear(1 , 2)\n",
    "        self.fc2 = nn.Linear(28 * 28, 784)\n",
    "        self.fc3 = nn.Linear(784, hidden)\n",
    "        self.fc4 = nn.Linear(hidden, 10)\n",
    "    def forward(self, x):\n",
    "        # x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class MLPBig(nn.Module):\n",
    "    def __init__(self, hidden):\n",
    "        super(MLPBig, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 28*28)\n",
    "        self.fc2 = nn.Linear(28*28, 285)\n",
    "        self.fc3 = nn.Linear(285, hidden)\n",
    "        self.fc4 = nn.Linear(hidden, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        # x = (x / 0.5 - 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59cbda45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  818.97 k, 100.000% Params, 818.97 KMac, 100.000% MACs, \n",
      "  (fc2): Linear(615.44 k, 75.148% Params, 615.44 KMac, 75.148% MACs, in_features=784, out_features=784, bias=True)\n",
      "  (fc3): Linear(200.96 k, 24.538% Params, 200.96 KMac, 24.538% MACs, in_features=784, out_features=256, bias=True)\n",
      "  (fc4): Linear(2.57 k, 0.314% Params, 2.57 KMac, 0.314% MACs, in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "FLOPs: 818.97 KMac\n",
      "Params: 818.97 k\n"
     ]
    }
   ],
   "source": [
    "model = MLP(256)\n",
    "with torch.cuda.device(0):\n",
    "    flops, params = get_model_complexity_info(model, (784,), as_strings=True)\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10c803aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPBig(\n",
      "  914.95 k, 100.000% Params, 914.95 KMac, 100.000% MACs, \n",
      "  (fc1): Linear(615.44 k, 67.265% Params, 615.44 KMac, 67.265% MACs, in_features=784, out_features=784, bias=True)\n",
      "  (fc2): Linear(223.72 k, 24.452% Params, 223.72 KMac, 24.452% MACs, in_features=784, out_features=285, bias=True)\n",
      "  (fc3): Linear(73.22 k, 8.002% Params, 73.22 KMac, 8.002% MACs, in_features=285, out_features=256, bias=True)\n",
      "  (fc4): Linear(2.57 k, 0.281% Params, 2.57 KMac, 0.281% MACs, in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "FLOPs: 914.95 KMac\n",
      "Params: 914.95 k\n"
     ]
    }
   ],
   "source": [
    "model = MLPBig(256)\n",
    "with torch.cuda.device(0):\n",
    "    flops, params = get_model_complexity_info(model, (784,), as_strings=True)\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac3d9bc",
   "metadata": {},
   "source": [
    "## EfficientKAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb9cacd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAN(\n",
      "  0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "  (layers): ModuleList(\n",
      "    (0-1): 2 x KANLinear(\n",
      "      0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "      (base_activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "FLOPs: 912 Mac\n",
      "Params: 813.06 k\n"
     ]
    }
   ],
   "source": [
    "model = EffKAN([784, 128, 10], grid_size=5, spline_order=3, sp_trainable=False, sb_trainable=False)\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "    flops, params = get_model_complexity_info(model, (784,), as_strings=True)\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f572b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAN(\n",
      "  0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "  (layers): ModuleList(\n",
      "    (0-1): 2 x KANLinear(\n",
      "      0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "      (base_activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "FLOPs: 912 Mac\n",
      "Params: 914.69 k\n"
     ]
    }
   ],
   "source": [
    "model = EffKAN([784, 128, 10], grid_size=5, spline_order=3, sp_trainable=True, sb_trainable=False)\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "    flops, params = get_model_complexity_info(model, (784,), as_strings=True)\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "789a5c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficient_KAN_Fix(\n",
      "  0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "  (model): KAN(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x KANLinear(\n",
      "        0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "        (base_activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "FLOPs: 912 Mac\n",
      "Params: 914.69 k\n"
     ]
    }
   ],
   "source": [
    "# KAN\n",
    "class Efficient_KAN(nn.Module):\n",
    "    def __init__(self, grid, device='cuda', output_size=10):\n",
    "        super(Efficient_KAN, self).__init__()\n",
    "        # self.layers = [input_size, 103, output_size] if dataset == datasets.MNIST \\\n",
    "        self.layers = [28*28, 128, output_size]\n",
    "        self.model = EffKAN(self.layers, grid_size=grid, sb_trainable=True, sp_trainable=True).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.layers[0])\n",
    "        x = self.model(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "# KAN\n",
    "class Efficient_KAN_Fix(nn.Module):\n",
    "    def __init__(self, grid, device='cuda', output_size=10):\n",
    "        super(Efficient_KAN_Fix, self).__init__()\n",
    "        # self.layers = [input_size, 103, output_size] if dataset == datasets.MNIST \\\n",
    "        self.layers = [28*28, 128, output_size]\n",
    "        self.model = EffKAN(self.layers, grid_size=grid, sb_trainable=False, sp_trainable=True).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.layers[0])\n",
    "        x = self.model(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "    flops, params = get_model_complexity_info(Efficient_KAN_Fix(grid=5), (784,), as_strings=True)\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b746bedf8c299",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## KAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bee29a5bbd28403",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:09:18.436795Z",
     "start_time": "2024-07-04T15:09:18.404734Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAN(\n",
      "  0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "  (biases): ModuleList(\n",
      "    (0): Linear(0, 0.000% Params, 0.0 Mac, 0.000% MACs, in_features=128, out_features=1, bias=False)\n",
      "    (1): Linear(0, 0.000% Params, 0.0 Mac, 0.000% MACs, in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      "  (act_fun): ModuleList(\n",
      "    (0-1): 2 x KANLayer(\n",
      "      0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "      (base_fun): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    )\n",
      "  )\n",
      "  (base_fun): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      ")\n",
      "FLOPs: 101.63 KMac\n",
      "Params: 813.06 k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/aless/Desktop/pykan/KAN-Continual_Learning/kan/KAN.py:333: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /opt/conda/conda-bld/pytorch_1716905979055/work/aten/src/ATen/native/ReduceOps.cpp:1807.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    }
   ],
   "source": [
    "model = KAN([784, 128, 10], grid=5, k=3, symbolic_enabled=False, sp_trainable=False, sb_trainable=False, bias_trainable=False)\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "    flops, params = get_model_complexity_info(model, (784,), valid=False, as_strings=True)\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38ac5a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAN(\n",
      "  0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "  (biases): ModuleList(\n",
      "    (0): Linear(0, 0.000% Params, 0.0 Mac, 0.000% MACs, in_features=128, out_features=1, bias=False)\n",
      "    (1): Linear(0, 0.000% Params, 0.0 Mac, 0.000% MACs, in_features=10, out_features=1, bias=False)\n",
      "  )\n",
      "  (act_fun): ModuleList(\n",
      "    (0-1): 2 x KANLayer(\n",
      "      0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "      (base_fun): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    )\n",
      "  )\n",
      "  (base_fun): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      ")\n",
      "FLOPs: 101.63 KMac\n",
      "Params: 914.69 k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/aless/Desktop/pykan/KAN-Continual_Learning/kan/KAN.py:333: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /opt/conda/conda-bld/pytorch_1716905979055/work/aten/src/ATen/native/ReduceOps.cpp:1807.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    }
   ],
   "source": [
    "model = KAN([784, 128, 10], grid=5, k=3, symbolic_enabled=False, sp_trainable=True, sb_trainable=False, bias_trainable=False)\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "    flops, params = get_model_complexity_info(model, (784,), valid=False, as_strings=True)\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba951c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Py_KAN_Fix(\n",
      "  0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "  (model): KAN(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (biases): ModuleList(\n",
      "      (0): Linear(0, 0.000% Params, 0.0 Mac, 0.000% MACs, in_features=128, out_features=1, bias=False)\n",
      "      (1): Linear(0, 0.000% Params, 0.0 Mac, 0.000% MACs, in_features=10, out_features=1, bias=False)\n",
      "    )\n",
      "    (act_fun): ModuleList(\n",
      "      (0-1): 2 x KANLayer(\n",
      "        0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "        (base_fun): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      )\n",
      "    )\n",
      "    (base_fun): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "  )\n",
      ")\n",
      "FLOPs: 101.63 KMac\n",
      "Params: 914.69 k\n"
     ]
    }
   ],
   "source": [
    "class Py_KAN_Fix(nn.Module):\n",
    "    def __init__(self, grid, device='cuda'):\n",
    "        super(Py_KAN_Fix, self).__init__()\n",
    "        # self.layers = [input_size, 73, 10] if dataset == datasets.MNIST \\\n",
    "        self.layers = [28*28, 128, 10]\n",
    "        self.model = KAN(self.layers, grid=grid, device=device, sb_trainable=False,\n",
    "                           sp_trainable=True, bias_trainable=False, symbolic_enabled=False).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.layers[0])\n",
    "        x = self.model(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "class Py_KAN(nn.Module):\n",
    "    def __init__(self, grid, device='cuda'):\n",
    "        super(Py_KAN, self).__init__()\n",
    "        # self.layers = [input_size, 73, 10] if dataset == datasets.MNIST \\\n",
    "        self.layers = [28*28, 128, 10]\n",
    "        self.model = KAN(self.layers, grid=grid, device=device, sb_trainable=True,\n",
    "                           sp_trainable=True, bias_trainable=True, symbolic_enabled=False).to(device)\n",
    "\n",
    "    # def train(self, epochs=5, on_epoch_end=None, lr=1, train_loader=None):\n",
    "    #     self.model.train(train_loader, test_loader, lr=lr, epochs=epochs, device=device,\n",
    "    #                      metrics=MulticlassAccuracy(num_classes=10).to(device), opt=\"Adam\",\n",
    "    #                      loss_fn=nn.NLLLoss())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.layers[0])\n",
    "        x = self.model(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "with torch.cuda.device(0):\n",
    "    flops, params = get_model_complexity_info(Py_KAN_Fix(grid=5), (784,), valid=False, as_strings=True)\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da627bc8",
   "metadata": {},
   "source": [
    "## Prova EffKAN vs KAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64d02e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAN(\n",
      "  0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "  (biases): ModuleList(\n",
      "    (0): Linear(0, 0.000% Params, 0.0 Mac, 0.000% MACs, in_features=2, out_features=1, bias=False)\n",
      "  )\n",
      "  (act_fun): ModuleList(\n",
      "    (0): KANLayer(\n",
      "      0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "      (base_fun): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    )\n",
      "  )\n",
      "  (base_fun): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      ")\n",
      "FLOPs: 100 Mac\n",
      "Params: 800\n"
     ]
    }
   ],
   "source": [
    "model = KAN([50, 2], grid=5, k=3, symbolic_enabled=False, sp_trainable=False, sb_trainable=False, bias_trainable=False)\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "    flops, params = get_model_complexity_info(model, (50,), eval=False, as_strings=True)\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01fcf6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAN(\n",
      "  0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "  (layers): ModuleList(\n",
      "    (0): KANLinear(\n",
      "      0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "      (base_activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "FLOPs: 50 Mac\n",
      "Params: 800\n"
     ]
    }
   ],
   "source": [
    "model = EffKAN([50, 2], grid_size=5, spline_order=3, sp_trainable=False, sb_trainable=False)\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "    flops, params = get_model_complexity_info(model, (50,), as_strings=True)\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96214347",
   "metadata": {},
   "source": [
    "# Convolutionals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad0fdd7",
   "metadata": {},
   "source": [
    "## Provo CKAN vs CONV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1939b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KAN_Convolutional_Layer + MLP\n",
    "class CKAN(nn.Module):\n",
    "    def __init__(self, device='cpu', wb_train=False, ws_train=False, ss_train=False):\n",
    "        super().__init__()\n",
    "        self.conv1 = KAN_Convolutional_Layer(\n",
    "            n_convs=5,\n",
    "            kernel_size=(3, 3),\n",
    "            grid_size=3,\n",
    "            device=device,\n",
    "            base_w_trainable=wb_train,\n",
    "            spline_s_trainable=ss_train,\n",
    "            spline_w_trainable=ws_train\n",
    "        )\n",
    "        self.conv2 = KAN_Convolutional_Layer(\n",
    "            n_convs=5,\n",
    "            kernel_size=(3, 3),\n",
    "            grid_size=3,\n",
    "            device=device,\n",
    "            base_w_trainable=wb_train,\n",
    "            spline_s_trainable=ss_train,\n",
    "            spline_w_trainable=ws_train\n",
    "        )\n",
    "        # self.bn1 = nn.BatchNorm2d(5)\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        self.linear1 = nn.Linear(14400, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.linear1(x)\n",
    "        # x = self.bn1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Conv2d + KAN\n",
    "class CONV(nn.Module):\n",
    "    def __init__(self, wb_train=True, ws_train=True, ss_train=True):\n",
    "        super(CONV, self).__init__()\n",
    "        # Convolutional layer, assuming an input with 1 channel (grayscale image)\n",
    "        # and producing 16 output channels, with a kernel size of 3x3\n",
    "        self.conv1 = nn.Conv2d(1, 5, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1169e25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CKAN(\n",
      "  14.4 k, 96.386% Params, 14.4 KMac, 8.256% MACs, \n",
      "  (conv1): KAN_Convolutional_Layer(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (convs): ModuleList(\n",
      "      (0-4): 5 x KAN_Convolution(\n",
      "        0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "        (conv): KANLinear(\n",
      "          0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "          (base_activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv2): KAN_Convolutional_Layer(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (convs): ModuleList(\n",
      "      (0-4): 5 x KAN_Convolution(\n",
      "        0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "        (conv): KANLinear(\n",
      "          0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "          (base_activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (flat): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  (linear1): Linear(14.4 k, 96.386% Params, 14.4 KMac, 8.256% MACs, in_features=14400, out_features=1, bias=True)\n",
      ")\n",
      "FLOPs: 174.42 KMac\n",
      "Params: 14.94 k\n",
      "CONV(\n",
      "  50, 100.000% Params, 39.2 KMac, 100.000% MACs, \n",
      "  (conv1): Conv2d(50, 100.000% Params, 39.2 KMac, 100.000% MACs, 1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "FLOPs: 39.2 KMac\n",
      "Params: 50\n"
     ]
    }
   ],
   "source": [
    "ckan = CKAN()\n",
    "kan = CONV()\n",
    "\n",
    "for model in [ckan, kan]:\n",
    "    with torch.cuda.device(0):\n",
    "        flops, params = get_model_complexity_info(model, (1, 28, 28,), as_strings=True)\n",
    "        print(f\"FLOPs: {flops}\")\n",
    "        print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083573e6",
   "metadata": {},
   "source": [
    "## CKAN_BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8c4db7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KAN_Convolutional_Layer + MLP\n",
    "class CKAN_BN(nn.Module):\n",
    "    def __init__(self, device='cpu', wb_train=True, ws_train=True, ss_train=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = KAN_Convolutional_Layer(\n",
    "            n_convs=5,\n",
    "            kernel_size=(3, 3),\n",
    "            device=device,\n",
    "            base_w_trainable=wb_train,\n",
    "            spline_s_trainable=ss_train,\n",
    "            spline_w_trainable=ws_train\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(5)\n",
    "\n",
    "        self.conv2 = KAN_Convolutional_Layer(\n",
    "            n_convs=5,\n",
    "            kernel_size=(3, 3),\n",
    "            device=device,\n",
    "            base_w_trainable=wb_train,\n",
    "            spline_s_trainable=ss_train,\n",
    "            spline_w_trainable=ws_train\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(25)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(\n",
    "            kernel_size=(2, 2)\n",
    "        )\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        self.linear1 = nn.Linear(625, 256)\n",
    "        self.linear2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.flat(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a44f2556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CKAN_BN(\n",
      "  162.89 k, 99.560% Params, 182.04 KMac, 73.973% MACs, \n",
      "  (conv1): KAN_Convolutional_Layer(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (convs): ModuleList(\n",
      "      (0-4): 5 x KAN_Convolution(\n",
      "        0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "        (conv): KANLinear(\n",
      "          0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "          (base_activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bn1): BatchNorm2d(10, 0.006% Params, 6.76 KMac, 2.747% MACs, 5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): KAN_Convolutional_Layer(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (convs): ModuleList(\n",
      "      (0-4): 5 x KAN_Convolution(\n",
      "        0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "        (conv): KANLinear(\n",
      "          0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "          (base_activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bn2): BatchNorm2d(50, 0.031% Params, 6.05 KMac, 2.458% MACs, 25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool2d(0, 0.000% Params, 6.41 KMac, 2.603% MACs, kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (flat): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  (linear1): Linear(160.26 k, 97.952% Params, 160.26 KMac, 65.121% MACs, in_features=625, out_features=256, bias=True)\n",
      "  (linear2): Linear(2.57 k, 1.571% Params, 2.57 KMac, 1.044% MACs, in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "FLOPs: 246.09 KMac\n",
      "Params: 163.61 k\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "    flops, params = get_model_complexity_info(CKAN_BN(wb_train=False, ss_train=False, ws_train=False), (1, 28, 28), eval=False, as_strings=True)\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f8fd95",
   "metadata": {},
   "source": [
    "## KANC_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "768c8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KAN_Convolutional_Layer + MLP (without Batch Norm)\n",
    "class KANC_MLP(nn.Module):\n",
    "    def __init__(self, device='cpu', wb_train=True, ws_train=True, ss_train=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = KAN_Convolutional_Layer(\n",
    "            n_convs=5,\n",
    "            kernel_size=(3, 3),\n",
    "            device=device,\n",
    "            base_w_trainable=wb_train,\n",
    "            spline_s_trainable=ss_train,\n",
    "            spline_w_trainable=ws_train\n",
    "        )\n",
    "\n",
    "        self.conv2 = KAN_Convolutional_Layer(\n",
    "            n_convs=5,\n",
    "            kernel_size=(3, 3),\n",
    "            device=device,\n",
    "            base_w_trainable=wb_train,\n",
    "            spline_s_trainable=ss_train,\n",
    "            spline_w_trainable=ws_train\n",
    "        )\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(\n",
    "            kernel_size=(2, 2)\n",
    "        )\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        self.linear1 = nn.Linear(625, 256)\n",
    "        self.linear2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.flat(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cefdd3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KANC_MLP(\n",
      "  162.83 k, 99.560% Params, 169.23 KMac, 70.605% MACs, \n",
      "  (conv1): KAN_Convolutional_Layer(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (convs): ModuleList(\n",
      "      (0-4): 5 x KAN_Convolution(\n",
      "        0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "        (conv): KANLinear(\n",
      "          0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "          (base_activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv2): KAN_Convolutional_Layer(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (convs): ModuleList(\n",
      "      (0-4): 5 x KAN_Convolution(\n",
      "        0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "        (conv): KANLinear(\n",
      "          0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "          (base_activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pool1): MaxPool2d(0, 0.000% Params, 6.41 KMac, 2.672% MACs, kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (flat): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  (linear1): Linear(160.26 k, 97.988% Params, 160.26 KMac, 66.861% MACs, in_features=625, out_features=256, bias=True)\n",
      "  (linear2): Linear(2.57 k, 1.571% Params, 2.57 KMac, 1.072% MACs, in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "FLOPs: 239.69 KMac\n",
      "Params: 163.55 k\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "    flops, params = get_model_complexity_info(KANC_MLP(wb_train=False, ss_train=False, ws_train=False), (1, 28, 28), eval=False, as_strings=True)\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e18b0c",
   "metadata": {},
   "source": [
    "## NormalConvsKAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1a3d760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv2d + KAN\n",
    "class NormalConvsKAN(nn.Module):\n",
    "    def __init__(self, wb_train=True, ws_train=True, ss_train=True):\n",
    "        super(NormalConvsKAN, self).__init__()\n",
    "        # Convolutional layer, assuming an input with 1 channel (grayscale image)\n",
    "        # and producing 16 output channels, with a kernel size of 3x3\n",
    "        self.conv1 = nn.Conv2d(1, 5, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(5)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(5, 5, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(5)\n",
    "        # self.conv3 = nn.Conv2d(5, 10, kernel_size=3, padding=1)\n",
    "\n",
    "        # Max pooling layer\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Flatten layer\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # KAN layer\n",
    "        self.kan1 = KANLinear(\n",
    "            980, # 245, # 90\n",
    "            20,\n",
    "            grid_size=5,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.01,\n",
    "            scale_base=1,\n",
    "            scale_spline=1,\n",
    "            base_activation=nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[0, 1],\n",
    "            base_w_trainable=wb_train,\n",
    "            spline_w_trainable=ws_train,\n",
    "            spline_s_trainable=ss_train)\n",
    "        self.kan2 = KANLinear(\n",
    "            20, # 245, # 90\n",
    "            10,\n",
    "            grid_size=5,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.01,\n",
    "            scale_base=1,\n",
    "            scale_spline=1,\n",
    "            base_activation=nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[0, 1],\n",
    "            base_w_trainable=wb_train,\n",
    "            spline_w_trainable=ws_train,\n",
    "            spline_s_trainable=ss_train)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = self.maxpool(x)\n",
    "        # x = F.relu(self.conv3(x))\n",
    "        # x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        print(x.shape)\n",
    "        x = self.kan1(x)\n",
    "        x = self.kan2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5f674af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 980])\n",
      "NormalConvsKAN(\n",
      "  300, 0.189% Params, 239.12 KMac, 94.934% MACs, \n",
      "  (conv1): Conv2d(50, 0.032% Params, 39.2 KMac, 15.563% MACs, 1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(10, 0.006% Params, 7.84 KMac, 3.113% MACs, 5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(230, 0.145% Params, 180.32 KMac, 71.590% MACs, 5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(10, 0.006% Params, 7.84 KMac, 3.113% MACs, 5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (maxpool): MaxPool2d(0, 0.000% Params, 3.92 KMac, 1.556% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  (kan1): KANLinear(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (base_activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "  )\n",
      "  (kan2): KANLinear(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (base_activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "  )\n",
      ")\n",
      "FLOPs: 251.88 KMac\n",
      "Params: 158.7 k\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "    flops, params = get_model_complexity_info(NormalConvsKAN(wb_train=False, ss_train=False, ws_train=False), (1, 28, 28), eval=False, as_strings=True)\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d82bf5",
   "metadata": {},
   "source": [
    "## ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2031d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv2d + MLP + (Dropout)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        # self.layers = [1, 64 * 7 * 7, 256, 10]\n",
    "        # self.layers = [1, 980, 256, 10]\n",
    "        self.layers = [1, 980, 161, 10]\n",
    "\n",
    "        self.conv1 = nn.Conv2d(self.layers[0], 5, kernel_size=3, padding='same')\n",
    "        self.conv2 = nn.Conv2d(5, 5, kernel_size=3, padding='same')\n",
    "\n",
    "        # self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding='same')\n",
    "        # self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding='same')\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.layers[1], self.layers[2])\n",
    "        self.fc2 = nn.Linear(self.layers[2], self.layers[3])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        #x = self.dropout1(x)\n",
    "\n",
    "        # x = F.relu(self.conv3(x))\n",
    "        # x = F.relu(self.conv4(x))\n",
    "        # x = self.maxpool(x)\n",
    "        # #x = self.dropout2(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fbc2a2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 980])\n",
      "ConvNet(\n",
      "  159.84 k, 100.000% Params, 383.0 KMac, 96.981% MACs, \n",
      "  (conv1): Conv2d(50, 0.031% Params, 39.2 KMac, 9.926% MACs, 1, 5, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (conv2): Conv2d(230, 0.144% Params, 180.32 KMac, 45.660% MACs, 5, 5, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (maxpool): MaxPool2d(0, 0.000% Params, 3.92 KMac, 0.993% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout1): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.25, inplace=False)\n",
      "  (dropout3): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
      "  (fc1): Linear(157.94 k, 98.811% Params, 157.94 KMac, 39.993% MACs, in_features=980, out_features=161, bias=True)\n",
      "  (fc2): Linear(1.62 k, 1.014% Params, 1.62 KMac, 0.410% MACs, in_features=161, out_features=10, bias=True)\n",
      ")\n",
      "FLOPs: 394.92 KMac\n",
      "Params: 159.84 k\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "    flops, params = get_model_complexity_info(ConvNet(), (1, 28, 28), eval=False, as_strings=True)\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1745f1",
   "metadata": {},
   "source": [
    "## KKAN_Convolutional_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5206afd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KAN_Convolutional_Layer + KAN\n",
    "class KKAN_Convolutional_Network(nn.Module):\n",
    "    def __init__(self, device='cpu', wb_train=True, ws_train=True, ss_train=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = KAN_Convolutional_Layer(\n",
    "            n_convs=5,\n",
    "            kernel_size=(3, 3),\n",
    "            device=device,\n",
    "            base_w_trainable=wb_train,\n",
    "            spline_s_trainable=ss_train,\n",
    "            spline_w_trainable=ws_train\n",
    "        )\n",
    "\n",
    "        self.conv2 = KAN_Convolutional_Layer(\n",
    "            n_convs=5,\n",
    "            kernel_size=(3, 3),\n",
    "            device=device,\n",
    "            base_w_trainable=wb_train,\n",
    "            spline_s_trainable=ss_train,\n",
    "            spline_w_trainable=ws_train\n",
    "        )\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(\n",
    "            kernel_size=(2, 2)\n",
    "        )\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        self.kan1 = KANLinear(\n",
    "            625,\n",
    "            31,\n",
    "            grid_size=5,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.01,\n",
    "            scale_base=1,\n",
    "            scale_spline=1,\n",
    "            base_activation=nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[0, 1],\n",
    "            base_w_trainable=wb_train,\n",
    "            spline_w_trainable=ws_train,\n",
    "            spline_s_trainable=ss_train\n",
    "        )\n",
    "        self.kan2 = KANLinear(\n",
    "            31,\n",
    "            10,\n",
    "            grid_size=5,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.01,\n",
    "            scale_base=1,\n",
    "            scale_spline=1,\n",
    "            base_activation=nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[0, 1],\n",
    "            base_w_trainable=wb_train,\n",
    "            spline_w_trainable=ws_train,\n",
    "            spline_s_trainable=ss_train\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.flat(x)\n",
    "\n",
    "        x = self.kan1(x)\n",
    "        x = self.kan2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "84252399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KKAN_Convolutional_Network(\n",
      "  0, 0.000% Params, 6.41 KMac, 9.007% MACs, \n",
      "  (conv1): KAN_Convolutional_Layer(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (convs): ModuleList(\n",
      "      (0-4): 5 x KAN_Convolution(\n",
      "        0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "        (conv): KANLinear(\n",
      "          0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "          (base_activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv2): KAN_Convolutional_Layer(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (convs): ModuleList(\n",
      "      (0-4): 5 x KAN_Convolution(\n",
      "        0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "        (conv): KANLinear(\n",
      "          0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "          (base_activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pool1): MaxPool2d(0, 0.000% Params, 6.41 KMac, 9.007% MACs, kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (flat): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  (kan1): KANLinear(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (base_activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "  )\n",
      "  (kan2): KANLinear(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (base_activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "  )\n",
      ")\n",
      "FLOPs: 71.11 KMac\n",
      "Params: 158.2 k\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "    flops, params = get_model_complexity_info(KKAN_Convolutional_Network(wb_train=False, ss_train=False, ws_train=False), (1, 28, 28), eval=False, as_strings=True)\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3e97bf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KAN_Convolutional_Layer + KAN\n",
    "class KANvNet(nn.Module):\n",
    "    def __init__(self, device='cpu', wb_train=True, ws_train=True, ss_train=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = KAN_Convolutional_Layer(\n",
    "            n_convs=5,\n",
    "            kernel_size=(3, 3),\n",
    "            device=device,\n",
    "            base_w_trainable=wb_train,\n",
    "            spline_s_trainable=ss_train,\n",
    "            spline_w_trainable=ws_train\n",
    "        )\n",
    "\n",
    "        # self.conv2 = KAN_Convolutional_Layer(\n",
    "        #     n_convs=5,\n",
    "        #     kernel_size=(3, 3),\n",
    "        #     device=device,\n",
    "        #     base_w_trainable=wb_train,\n",
    "        #     spline_s_trainable=ss_train,\n",
    "        #     spline_w_trainable=ws_train\n",
    "        # )\n",
    "\n",
    "        # self.pool1 = nn.MaxPool2d(\n",
    "        #     kernel_size=(2, 2)\n",
    "        # )\n",
    "\n",
    "        # self.flat = nn.Flatten()\n",
    "\n",
    "        # self.kan1 = KANLinear(\n",
    "        #     625,\n",
    "        #     31,\n",
    "        #     grid_size=5,\n",
    "        #     spline_order=3,\n",
    "        #     scale_noise=0.01,\n",
    "        #     scale_base=1,\n",
    "        #     scale_spline=1,\n",
    "        #     base_activation=nn.SiLU,\n",
    "        #     grid_eps=0.02,\n",
    "        #     grid_range=[0, 1],\n",
    "        #     base_w_trainable=wb_train,\n",
    "        #     spline_w_trainable=ws_train,\n",
    "        #     spline_s_trainable=ss_train\n",
    "        # )\n",
    "        # self.kan2 = KANLinear(\n",
    "        #     31,\n",
    "        #     10,\n",
    "        #     grid_size=5,\n",
    "        #     spline_order=3,\n",
    "        #     scale_noise=0.01,\n",
    "        #     scale_base=1,\n",
    "        #     scale_spline=1,\n",
    "        #     base_activation=nn.SiLU,\n",
    "        #     grid_eps=0.02,\n",
    "        #     grid_range=[0, 1],\n",
    "        #     base_w_trainable=wb_train,\n",
    "        #     spline_w_trainable=ws_train,\n",
    "        #     spline_s_trainable=ss_train\n",
    "        # )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        # x = self.pool1(x)\n",
    "\n",
    "        # x = self.conv2(x)\n",
    "        # x = self.pool1(x)\n",
    "        # x = self.flat(x)\n",
    "\n",
    "        # x = self.kan1(x)\n",
    "        # x = self.kan2(x)\n",
    "        # x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5ad3a869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KANvNet(\n",
      "  0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "  (conv1): KAN_Convolutional_Layer(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (convs): ModuleList(\n",
      "      (0-4): 5 x KAN_Convolution(\n",
      "        0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "        (conv): KANLinear(\n",
      "          0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "          (base_activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "FLOPs: 30.42 KMac\n",
      "Params: 360\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "    flops, params = get_model_complexity_info(KANvNet(wb_train=False, ss_train=False, ws_train=True), (1, 28, 28), eval=False, as_strings=True)\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"Params: {params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
